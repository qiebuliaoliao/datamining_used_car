{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务五——模型融合\n",
    "\n",
    "\n",
    "有时候，几个基模型的预测结果可能都不怎么样，但是，将不同的模型结果融合，有可能会得到较好的结果。\n",
    "\n",
    "常用的模型融合方法有：\n",
    "\n",
    "- 简单加权融合法\n",
    "\n",
    "- stacking\n",
    "\n",
    "- boosting/bagging\n",
    "\n",
    "这里我们以二手车价格预测为例，分别采用简单加权平均法和stacking方法进行模型的融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先导入各种需要的包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "# from mlxtend.plotting import plot_learning_curves\n",
    "# from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA,FastICA,FactorAnalysis,SparsePCA\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_data shape:  (150000, 31)\n",
      "Test_data shape:  (50000, 30)\n"
     ]
    }
   ],
   "source": [
    "# 导入数据\n",
    "path = 'C:/python_temp/'\n",
    "Train_data = pd.read_csv(path + 'data/used_car_train_20200313.csv', sep=' ')\n",
    "Test_data = pd.read_csv(path + 'data/used_car_testA_20200313.csv', sep=' ')\n",
    "\n",
    "print('Train_data shape: ',Train_data.shape)\n",
    "print('Test_data shape: ',Test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SaleID', 'name', 'regDate', 'model', 'brand', 'bodyType', 'fuelType',\n",
      "       'gearbox', 'power', 'kilometer', 'regionCode', 'seller', 'offerType',\n",
      "       'creatDate', 'price', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'v_6',\n",
      "       'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13', 'v_14'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 区分数值特征\n",
    "numerical_cols = Train_data.select_dtypes(exclude = 'object').columns\n",
    "print(numerical_cols)\n",
    "feature_cols = [col for col in numerical_cols if col not in ['SaleID','name','regDate','price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (150000, 26)\n",
      "X test shape: (50000, 26)\n"
     ]
    }
   ],
   "source": [
    "# 提取数值特征\n",
    "X_data = Train_data[feature_cols]\n",
    "Y_data = Train_data['price']\n",
    "\n",
    "X_test  = Test_data[feature_cols]\n",
    "\n",
    "print('X train shape:',X_data.shape)\n",
    "print('X test shape:',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个统计函数\n",
    "def Sta_inf(data):\n",
    "    print('_min',np.min(data))\n",
    "    print('_max:',np.max(data))\n",
    "    print('_mean',np.mean(data))\n",
    "    print('_ptp',np.ptp(data))\n",
    "    print('_std',np.std(data))\n",
    "    print('_var',np.var(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sta of label:\n",
      "_min 11\n",
      "_max: 99999\n",
      "_mean 5923.327333333334\n",
      "_ptp 99988\n",
      "_std 7501.973469876438\n",
      "_var 56279605.94272992\n"
     ]
    }
   ],
   "source": [
    "print('Sta of label:')\n",
    "Sta_inf(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data.fillna(-1)\n",
    "X_test = X_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义各种模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_lr(x_train,y_train):\n",
    "    reg_model = linear_model.LinearRegression()\n",
    "    reg_model.fit(x_train,y_train)\n",
    "    return reg_model\n",
    "\n",
    "def build_model_ridge(x_train,y_train):\n",
    "    reg_model = linear_model.Ridge(alpha=0.8)#alphas=range(1,100,5)\n",
    "    reg_model.fit(x_train,y_train)\n",
    "    return reg_model\n",
    "\n",
    "def build_model_lasso(x_train,y_train):\n",
    "    reg_model = linear_model.LassoCV()\n",
    "    reg_model.fit(x_train,y_train)\n",
    "    return reg_model\n",
    "\n",
    "def build_model_gbdt(x_train,y_train):\n",
    "    estimator =GradientBoostingRegressor(loss='ls',subsample= 0.85,max_depth= 5,n_estimators = 100)\n",
    "    param_grid = { \n",
    "            'learning_rate': [0.05,0.08,0.1,0.2],\n",
    "            }\n",
    "    gbdt = GridSearchCV(estimator, param_grid,cv=3)\n",
    "    gbdt.fit(x_train,y_train)\n",
    "    print(gbdt.best_params_)\n",
    "    # print(gbdt.best_estimator_ )\n",
    "    return gbdt\n",
    "\n",
    "def build_model_xgb(x_train,y_train):\n",
    "    model = xgb.XGBRegressor(n_estimators=120, learning_rate=0.08, gamma=0, subsample=0.8,\\\n",
    "        colsample_bytree=0.9, max_depth=5) #, objective ='reg:squarederror'\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def build_model_lgb(x_train,y_train):\n",
    "    estimator = lgb.LGBMRegressor(num_leaves=63,n_estimators = 100)\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "    }\n",
    "    gbm = GridSearchCV(estimator, param_grid)\n",
    "    gbm.fit(x_train, y_train)\n",
    "    return gbm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用xgboost训练模型，五折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mae: 600.0127885014529\n",
      "Val mae 691.9976473362078\n"
     ]
    }
   ],
   "source": [
    "## xgb\n",
    "xgr = xgb.XGBRegressor(n_estimators=120, learning_rate=0.1, subsample=0.8,\\\n",
    "        colsample_bytree=0.9, max_depth=7) # ,objective ='reg:squarederror'\n",
    "\n",
    "scores_train = []\n",
    "scores = []\n",
    "\n",
    "## 5折交叉验证方式\n",
    "sk=StratifiedKFold(n_splits=5,shuffle=True,random_state=0)\n",
    "for train_ind,val_ind in sk.split(X_data,Y_data):\n",
    "    \n",
    "    train_x=X_data.iloc[train_ind].values\n",
    "    train_y=Y_data.iloc[train_ind]\n",
    "    val_x=X_data.iloc[val_ind].values\n",
    "    val_y=Y_data.iloc[val_ind]\n",
    "    \n",
    "    xgr.fit(train_x,train_y)\n",
    "    pred_train_xgb=xgr.predict(train_x)\n",
    "    pred_xgb=xgr.predict(val_x)\n",
    "    \n",
    "    score_train = mean_absolute_error(train_y,pred_train_xgb)\n",
    "    scores_train.append(score_train)\n",
    "    score = mean_absolute_error(val_y,pred_xgb)\n",
    "    scores.append(score)\n",
    "\n",
    "print('Train mae:',np.mean(score_train))\n",
    "print('Val mae',np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分数据集，并且分别用不同的模型来训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict LR...\n",
      "Predict Ridge...\n",
      "Predict Lasso...\n",
      "Predict GBDT...\n",
      "{'learning_rate': 0.2}\n"
     ]
    }
   ],
   "source": [
    "## Split data with val\n",
    "x_train,x_val,y_train,y_val = train_test_split(X_data,Y_data,test_size=0.3)\n",
    "\n",
    "## Train and Predict\n",
    "print('Predict LR...')\n",
    "model_lr = build_model_lr(x_train,y_train)\n",
    "val_lr = model_lr.predict(x_val)\n",
    "subA_lr = model_lr.predict(X_test)\n",
    "\n",
    "print('Predict Ridge...')\n",
    "model_ridge = build_model_ridge(x_train,y_train)\n",
    "val_ridge = model_ridge.predict(x_val)\n",
    "subA_ridge = model_ridge.predict(X_test)\n",
    "\n",
    "print('Predict Lasso...')\n",
    "model_lasso = build_model_lasso(x_train,y_train)\n",
    "val_lasso = model_lasso.predict(x_val)\n",
    "subA_lasso = model_lasso.predict(X_test)\n",
    "\n",
    "print('Predict GBDT...')\n",
    "model_gbdt = build_model_gbdt(x_train,y_train)\n",
    "val_gbdt = model_gbdt.predict(x_val)\n",
    "subA_gbdt = model_gbdt.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict XGB...\n",
      "predict lgb...\n"
     ]
    }
   ],
   "source": [
    "print('predict XGB...')\n",
    "model_xgb = build_model_xgb(x_train,y_train)\n",
    "val_xgb = model_xgb.predict(x_val)\n",
    "subA_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "print('predict lgb...')\n",
    "model_lgb = build_model_lgb(x_train,y_train)\n",
    "val_lgb = model_lgb.predict(x_val)\n",
    "subA_lgb = model_lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sta inf of lgb:\n",
      "_min -190.48370439978186\n",
      "_max: 88111.08615141825\n",
      "_mean 5928.052513541221\n",
      "_ptp 88301.56985581803\n",
      "_std 7375.287827160764\n",
      "_var 54394870.53346575\n"
     ]
    }
   ],
   "source": [
    "print('Sta inf of lgb:')\n",
    "Sta_inf(subA_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单加权融合\n",
    "\n",
    "这里使用简单加权平均，将lgb、xgb、gbdt三个模型进行融合，每个模型的权重为1/3，也可以有不同的尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Weighted of val: 732.3789768244402\n",
      "Sta inf:\n",
      "_min -5419.36222704956\n",
      "_max: 89668.88448530043\n",
      "_mean 5927.775914256101\n",
      "_ptp 95088.24671234998\n",
      "_std 7360.818933341568\n",
      "_var 54181655.3694397\n"
     ]
    }
   ],
   "source": [
    "def Weighted_method(test_pre1,test_pre2,test_pre3,w=[1/3,1/3,1/3]):\n",
    "    Weighted_result = w[0]*pd.Series(test_pre1)+w[1]*pd.Series(test_pre2)+w[2]*pd.Series(test_pre3)\n",
    "    return Weighted_result\n",
    "\n",
    "## Init the Weight\n",
    "w = [0.3,0.4,0.3]\n",
    "\n",
    "## 测试验证集准确度\n",
    "val_pre = Weighted_method(val_lgb,val_xgb,val_gbdt,w)\n",
    "MAE_Weighted = mean_absolute_error(y_val,val_pre)\n",
    "print('MAE of Weighted of val:',MAE_Weighted)\n",
    "\n",
    "## 预测数据部分\n",
    "subA = Weighted_method(subA_lgb,subA_xgb,subA_gbdt,w)\n",
    "print('Sta inf:')\n",
    "Sta_inf(subA)\n",
    "## 生成提交文件\n",
    "sub = pd.DataFrame()\n",
    "sub['SaleID'] = X_test.index\n",
    "sub['price'] = subA\n",
    "sub.to_csv(path + 'data/sub_Weighted.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of lr: 2584.273041775682\n"
     ]
    }
   ],
   "source": [
    "## 与简单的LR（线性回归）进行对比\n",
    "val_lr_pred = model_lr.predict(x_val)\n",
    "MAE_lr = mean_absolute_error(y_val,val_lr_pred)\n",
    "print('MAE of lr:',MAE_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking融合\n",
    "\n",
    "\n",
    "stacking的思路就是，以两层为例，第一层用几个不同的基学习器对训练数据进行训练，得到预测值，第二层用一个简单的模型，将第一层模型得到的预测值作为特征，真实标签作为标签，进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starking\n",
    "\n",
    "## 第一层\n",
    "train_lgb_pred = model_lgb.predict(x_train)\n",
    "train_xgb_pred = model_xgb.predict(x_train)\n",
    "train_gbdt_pred = model_gbdt.predict(x_train)\n",
    "\n",
    "Strak_X_train = pd.DataFrame()\n",
    "Strak_X_train['Method_1'] = train_lgb_pred\n",
    "Strak_X_train['Method_2'] = train_xgb_pred\n",
    "Strak_X_train['Method_3'] = train_gbdt_pred\n",
    "\n",
    "Strak_X_val = pd.DataFrame()\n",
    "Strak_X_val['Method_1'] = val_lgb\n",
    "Strak_X_val['Method_2'] = val_xgb\n",
    "Strak_X_val['Method_3'] = val_gbdt\n",
    "\n",
    "Strak_X_test = pd.DataFrame()\n",
    "Strak_X_test['Method_1'] = subA_lgb\n",
    "Strak_X_test['Method_2'] = subA_xgb\n",
    "Strak_X_test['Method_3'] = subA_gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method_1</th>\n",
       "      <th>Method_2</th>\n",
       "      <th>Method_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39214.004293</td>\n",
       "      <td>40517.609375</td>\n",
       "      <td>39765.925665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>259.098035</td>\n",
       "      <td>267.439880</td>\n",
       "      <td>110.522989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7333.709130</td>\n",
       "      <td>7516.027344</td>\n",
       "      <td>7340.917360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11709.585490</td>\n",
       "      <td>11463.902344</td>\n",
       "      <td>11212.708081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>544.558460</td>\n",
       "      <td>550.346069</td>\n",
       "      <td>551.113673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Method_1      Method_2      Method_3\n",
       "0  39214.004293  40517.609375  39765.925665\n",
       "1    259.098035    267.439880    110.522989\n",
       "2   7333.709130   7516.027344   7340.917360\n",
       "3  11709.585490  11463.902344  11212.708081\n",
       "4    544.558460    550.346069    551.113673"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Strak_X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了防止过拟合，第二层用简单的模型，这里使用的是线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of Stacking-LR: 627.0036572393954\n",
      "MAE of Stacking-LR: 723.9150641754426\n",
      "Predict Stacking-LR...\n"
     ]
    }
   ],
   "source": [
    "## level2-method \n",
    "model_lr_Stacking = build_model_lr(Strak_X_train,y_train)\n",
    "## 训练集\n",
    "train_pre_Stacking = model_lr_Stacking.predict(Strak_X_train)\n",
    "print('MAE of Stacking-LR:',mean_absolute_error(y_train,train_pre_Stacking))\n",
    "\n",
    "## 验证集\n",
    "val_pre_Stacking = model_lr_Stacking.predict(Strak_X_val)\n",
    "print('MAE of Stacking-LR:',mean_absolute_error(y_val,val_pre_Stacking))\n",
    "\n",
    "## 预测集\n",
    "print('Predict Stacking-LR...')\n",
    "subA_Stacking = model_lr_Stacking.predict(Strak_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "subA_Stacking[subA_Stacking<10]=10  ## 去除过小的预测值\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['SaleID'] = Test_data.SaleID\n",
    "sub['price'] = subA_Stacking\n",
    "sub.to_csv(path + 'data/sub_Stacking.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sta inf:\n",
      "_min 10.0\n",
      "_max: 89388.35930978386\n",
      "_mean 5927.708197907798\n",
      "_ptp 89378.35930978386\n",
      "_std 7415.173475484684\n",
      "_var 54984797.6715316\n"
     ]
    }
   ],
   "source": [
    "print('Sta inf:')\n",
    "Sta_inf(subA_Stacking)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
